{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0m006lg2aBlo"
      },
      "source": [
        "# CH-07 å¹´å ±å•ç­”æ©Ÿå™¨äºº"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDeujD32ClKr"
      },
      "source": [
        "## 7-2 å–å¾—å¹´å ±"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9LdYpop4TP4"
      },
      "source": [
        "### 1ï¸âƒ£  åŒ¯å…¥å¥—ä»¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DMJyrZh6Z89A"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T05v3t_u4gxF"
      },
      "source": [
        "### 2ï¸âƒ£ å»ºç«‹å‡½å¼-å–å¾—å¹´å ±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RswezCvohjXv"
      },
      "outputs": [],
      "source": [
        "def annual_report(id,y):\n",
        "  url = 'https://doc.twse.com.tw/server-java/t57sb01'\n",
        "  # å»ºç«‹ POST è«‹æ±‚çš„è¡¨å–®\n",
        "  data = {\n",
        "      \"id\":\"\",\n",
        "      \"key\":\"\",\n",
        "      \"step\":\"1\",\n",
        "      \"co_id\":id,\n",
        "      \"year\":y,\n",
        "      \"seamon\":\"\",\n",
        "      \"mtype\":'F',\n",
        "      \"dtype\":'F04'\n",
        "  }\n",
        "  try:\n",
        "    # ç™¼é€ POST è«‹æ±‚\n",
        "    response = requests.post(url, data=data)\n",
        "    # å–å¾—å›æ‡‰å¾Œæ“·å–æª”æ¡ˆåç¨±\n",
        "    link=BeautifulSoup(response.text, 'html.parser')\n",
        "    link1=link.find('a').text\n",
        "    print(link1)\n",
        "  except Exception as e:\n",
        "    print(f\"ç™¼ç”Ÿ{e}éŒ¯èª¤\")\n",
        "  # å»ºç«‹ç¬¬äºŒå€‹ POST è«‹æ±‚çš„è¡¨å–®\n",
        "  data2 = {\n",
        "      'step':'9',\n",
        "      'kind':'F',\n",
        "      'co_id':id,\n",
        "      'filename':link1 # æª”æ¡ˆåç¨±\n",
        "  }\n",
        "  try:\n",
        "    # ç™¼é€ POST è«‹æ±‚\n",
        "    response = requests.post(url, data=data2)\n",
        "    link=BeautifulSoup(response.text, 'html.parser')\n",
        "    link1=link.find('a')\n",
        "    # å–å¾— PDF é€£çµ\n",
        "    link2 = link1.get('href')\n",
        "    print(link2)\n",
        "  except Exception as e:\n",
        "    print(f\"ç™¼ç”Ÿ{e}éŒ¯èª¤\")\n",
        "  # ç™¼é€ GET è«‹æ±‚\n",
        "  try:\n",
        "    response = requests.get('https://doc.twse.com.tw' + link2)\n",
        "    # å–å¾— PDF è³‡æ–™\n",
        "    with open(y + '_' + id + '.pdf', 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print('OK')\n",
        "  except Exception as e:\n",
        "    print(f\"ç™¼ç”Ÿ{e}éŒ¯èª¤\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e2fZDvP4j7U"
      },
      "source": [
        "### 3ï¸âƒ£ å‘¼å«å‡½å¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhWwMVnSNnCW",
        "outputId": "6a46bbaa-641e-4e00-f414-574e471038ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023_2330_20240604F04.pdf\n",
            "/pdf/2023_2330_20240604F04_20250216_065514.pdf\n",
            "OK\n"
          ]
        }
      ],
      "source": [
        "annual_report('2330','113')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8llLs86CFIwr"
      },
      "source": [
        "## 7-3 å¹´å ±å•ç­”"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "langchain ä»¥æ›´æ–°è‡³æ–°ç‰ˆå¯«æ³•ï¼ŒèˆŠç‰ˆå¯åƒè€ƒï¼š\n",
        "https://colab.research.google.com/drive/16x0mUitJjH0PZx7kk2Kew2MSlkB9G_lA"
      ],
      "metadata": {
        "id": "YuNOeoW0t5Mm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNeEBVGe4nm-"
      },
      "source": [
        "###4ï¸âƒ£ å®‰è£ç›¸é—œå¥—ä»¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUn2DtL56u-K",
        "outputId": "b483d920-cccd-4c92-b9bd-d5f8e4411f43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (4.12.2)\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.18)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.17-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.35)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Downloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.17-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, pypdfium2, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, pdfminer.six, dataclasses-json, pdfplumber, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.17 marshmallow-3.26.1 mypy-extensions-1.0.0 pdfminer.six-20231228 pdfplumber-0.11.5 pydantic-settings-2.7.1 pypdfium2-4.30.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.0.9-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.8.4)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.3.35)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (2.10.6)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.160.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.25.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.26.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (0.3.8)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (24.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.27.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (0.23.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.2.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (1.3.1)\n",
            "Downloading langchain_google_genai-2.0.9-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, langchain-google-genai\n",
            "Successfully installed filetype-1.2.0 langchain-google-genai-2.0.9\n"
          ]
        }
      ],
      "source": [
        "!pip install pydantic\n",
        "!pip install pdfplumber langchain langchain_community\n",
        "!pip install langchain-google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VceyfBhx4qRW"
      },
      "source": [
        "###  5ï¸âƒ£ åŒ¯å…¥ç›¸é—œå¥—ä»¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "G4fv5tYU60ux"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "from langchain_community.document_loaders import PDFPlumberLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import InMemoryVectorStore\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC-KWjg54sh2"
      },
      "source": [
        "### 6ï¸âƒ£ è¨­å®šç’°å¢ƒè®Šæ•¸å’Œå»ºç«‹ Google Gemini æ¨¡å‹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UNjmx9zCGEV9",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "llm_model = ChatGoogleGenerativeAI(\n",
        "    api_key = GEMINI_API_KEY,\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4axN95S4u2F"
      },
      "source": [
        "### 7ï¸âƒ£ å»ºç«‹å‡½å¼-å»ºç«‹å‘é‡è³‡æ–™åº«"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vpsrgVqTPsNn"
      },
      "outputs": [],
      "source": [
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "\n",
        "def build_vector_db(file_path, size, overlap):\n",
        "    loader = PDFPlumberLoader(file_path)\n",
        "    doc = loader.load()\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=size,\n",
        "        chunk_overlap=overlap)\n",
        "    docs = text_splitter.split_documents(doc)\n",
        "    db = InMemoryVectorStore.from_documents(docs, embeddings)\n",
        "    return db"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkM4Wymz4xld"
      },
      "source": [
        "### 8ï¸âƒ£  å‘¼å«å‡½å¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4RxY2097irW"
      },
      "outputs": [],
      "source": [
        "db = build_vector_db('/content/113_2330.pdf', 500, 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8WOOFCp4z0l"
      },
      "source": [
        "### 9ï¸âƒ£ æŸ¥è©¢ç›¸é—œè³‡æ–™"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRF0tJ61U5hg"
      },
      "outputs": [],
      "source": [
        "similarity_docs = db.similarity_search(\"ç ”ç™¼çš„ç”¢å“\", k=5)\n",
        "for i in similarity_docs:\n",
        "    print(i.page_content)\n",
        "    print('_________')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgpzZOij438G"
      },
      "source": [
        "### ğŸ”Ÿ  åŒ¯å…¥å•ç­”ç›¸é—œå¥—ä»¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnsilIt1JmDs"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import RetrievalQA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9a6x7na46RM"
      },
      "source": [
        "### 1ï¸âƒ£1ï¸âƒ£  å»ºç«‹å‡½å¼-å•ç­”ç¨‹å¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idLyQ6lVFMUD"
      },
      "outputs": [],
      "source": [
        "# æç¤ºæ¨¡æ¿\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\n",
        "     \"ä½ æ˜¯ä¸€å€‹æ ¹æ“šå¹´å ±è³‡æ–™èˆ‡ä¸Šä¸‹æ–‡ä½œå›ç­”çš„åŠ©æ‰‹,\"\n",
        "     \"å¦‚æœæœ‰æ˜ç¢ºæ•¸æ“šæˆ–æŠ€è¡“(ç”¢å“)åç¨±å¯ä»¥ç”¨æ•¸æ“šæˆ–åç¨±å›ç­”,\"\n",
        "     \"å›ç­”ä»¥ç¹é«”ä¸­æ–‡ç‚ºä¸»ã€‚\"\n",
        "     \"{context}\"),\n",
        "    (\"human\",\"{question}\")])\n",
        "\n",
        "# å»ºç«‹å•ç­”å‡½å¼\n",
        "def question_and_answer(question):\n",
        "    retrievalQA = RetrievalQA.from_llm(\n",
        "        llm=llm_model,\n",
        "        prompt=prompt,\n",
        "        return_source_documents=True,\n",
        "        retriever=db.as_retriever(\n",
        "        search_kwargs={'k':8}))\n",
        "    answer = retrievalQA.invoke(question)\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4UM2Kl148uW"
      },
      "source": [
        "### 1ï¸âƒ£2ï¸âƒ£ å»ºç«‹è¿´åœˆé€²è¡Œå•ç­”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xyejx1Ic8qQk"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "    question = input(\"è¼¸å…¥å•é¡Œ:\")\n",
        "    if not question.strip():\n",
        "        break\n",
        "    result = question_and_answer(question)\n",
        "    print(result['result'])\n",
        "    print('_________')\n",
        "    #print(result[\"source_documents\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzAmbDDYFDkE"
      },
      "source": [
        "## 7-4 å¹´å ±ç¸½çµèˆ‡åˆ†æ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4I10Pe8Y4-5F"
      },
      "source": [
        "### 1ï¸âƒ£3ï¸âƒ£ å›ç­”çµæœåŠåŸå§‹è³‡æ–™"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o65edAvKXUH5"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.summarize import load_summarize_chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr2Wz0MG5Avz"
      },
      "source": [
        "### 1ï¸âƒ£4ï¸âƒ£ ç¸½çµåŸå§‹è³‡æ–™"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# å»ºç«‹é—œéµå­—ä¸²åˆ—\n",
        "key_word = ['æ­£åœ¨é–‹ç™¼çš„ç”¢å“åŠéŠ·å”®ç‹€æ³',\n",
        "            'å¸‚å ´ç­–ç•¥çš„èª¿æ•´æˆ–è®ŠåŒ–',\n",
        "            'å…¬å¸é æœŸæœªä¾†å±•æœ›',\n",
        "            'ç¸½ç‡Ÿæ”¶ã€ç¨…å‰æ·¨åˆ©çš„æˆé•·æˆ–è®Šå‹•åˆ†æ',\n",
        "            'åœ‹éš›ç«¶çˆ­ä»¥åŠæµ·å¤–å¸‚å ´éŠ·å”®æƒ…å½¢']\n",
        "\n",
        "data_list = []\n",
        "for word in key_word:\n",
        "    data = db.similarity_search(word, k=3)\n",
        "    # æ•´åˆ Document ä¸²åˆ—\n",
        "    data_list += data\n",
        "\n",
        "# å»ºç«‹æç¤ºè¨Šæ¯ä¸²åˆ—\n",
        "prompt_template = [(\"system\",\"ä½ çš„ä»»å‹™æ˜¯å°å¹´å ±è³‡è¨Šé€²è¡Œæ‘˜è¦ç¸½çµã€‚\"\n",
        "                    \"ä»¥ä¸‹ç‚ºæä¾›çš„å¹´å ±è³‡è¨Šï¼š{text},\"\n",
        "                    \"è«‹çµ¦æˆ‘é‡é»æ•¸æ“š, å¦‚éŠ·å”®å¢é•·æƒ…å½¢ã€ç‡Ÿæ”¶è®ŠåŒ–ã€é–‹ç™¼é …ç›®ç­‰,\"\n",
        "                    \"æœ€å¾Œè«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡è¼¸å‡ºå ±å‘Š\")]\n",
        "prompt = ChatPromptTemplate.from_messages(messages=prompt_template)"
      ],
      "metadata": {
        "id": "37griuhHP0im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "220bNY7y5Cs2"
      },
      "source": [
        "### 1ï¸âƒ£5ï¸âƒ£  å‘¼å«å‡½å¼"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "refine_chain = load_summarize_chain(llm=llm_model,\n",
        "                                    chain_type='stuff',\n",
        "                                    prompt=prompt)\n",
        "summary_refine = refine_chain.invoke({\"input_documents\": data_list})\n",
        "print(summary_refine['output_text'])"
      ],
      "metadata": {
        "id": "l2XTY8L7Ppnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtiJJipA5I9-"
      },
      "source": [
        "### 1ï¸âƒ£6ï¸âƒ£  æå–é—œéµå­—\n",
        "ä½¿ç”¨ MMR æœå°‹æ–¹æ³•"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import CommaSeparatedListOutputParser, StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnableSequence\n",
        "\n",
        "word_prompt = PromptTemplate.from_template(\n",
        "     \"å¾{input}è¯æƒ³å‡º4å€‹èˆ‡å¹´å ±åˆ†ææœ‰é—œçš„é‡è¦é—œéµå­—,\"\\\n",
        "     \"è«‹ç¢ºä¿å›ç­”å…·æœ‰å…·æœ‰é—œè¯æ€§ã€å¤šæ¨£æ€§å’Œè®ŠåŒ–æ€§ã€‚ \\n \"\n",
        "     \"åƒ…å›è¦†é—œéµå­—, ä¸¦ä»¥åŠå½¢é€—è™Ÿèˆ‡ç©ºæ ¼ä¾†åˆ†éš”ã€‚ä¸è¦åŠ å…¥å…¶ä»–å…§å®¹\")\n",
        "\n",
        "word_chain = word_prompt | llm_model | CommaSeparatedListOutputParser()\n",
        "print(word_chain.invoke({\"input\": \"å…¬å¸çš„ç‡Ÿé‹ç‹€æ³å¦‚ä½•?\"}))"
      ],
      "metadata": {
        "id": "zMeR0jjh2_5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKilRAeA5GNG"
      },
      "source": [
        "### 1ï¸âƒ£7ï¸âƒ£ è¨­å®š AI è§’è‰²è®“å…¶åˆ†æå ±å‘Š"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_prompt = PromptTemplate.from_template(\n",
        "    \"ä½ ç¾åœ¨æ˜¯ä¸€ä½å°ˆæ¥­çš„è‚¡ç¥¨åˆ†æå¸«,\"\n",
        "    \"æœƒä»¥è©³ç´°ã€åš´è¬¹çš„è§’åº¦é‡å° {key_words} é€²è¡Œå¹´å ±åˆ†æ,\"\n",
        "    \"è«‹æåŠé—œæ–¼ç‡Ÿæ”¶ã€æ˜¯å¦æˆé•·ä»¥åŠåˆ©æ½¤ç­‰é‡è¦æ•¸å­—,\"\n",
        "    \"æœ€å¾Œç”Ÿæˆä¸€ä»½å°ˆæ¥­çš„è¶¨å‹¢åˆ†æå ±å‘Šã€‚\"\n",
        "    \"ä»¥ä¸‹ç‚ºå¹´å ±è³‡æ–™ï¼š{data_content}\")\n",
        "\n",
        "data_chain = data_prompt | llm_model | StrOutputParser()"
      ],
      "metadata": {
        "id": "y4nY5fkpVKlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3_A78R65LAd"
      },
      "source": [
        "### 1ï¸âƒ£8ï¸âƒ£ æ•´åˆå‡½å¼"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_chain(input):\n",
        "    # æœå°‹ã€Œå•é¡Œã€çš„ç›¸é—œè³‡æ–™\n",
        "    data = db.max_marginal_relevance_search(input, fetch_k=5, k=2)\n",
        "\n",
        "    # ç¬¬ä¸€å€‹ Chain å…ƒä»¶, å»ºç«‹ã€Œé—œéµå­—ã€ä¸²åˆ—\n",
        "    word_list = word_chain.invoke({\"input\": input})\n",
        "\n",
        "    # æœå°‹ã€Œé—œéµå­—ã€çš„ç›¸é—œè³‡æ–™\n",
        "    for word in word_list:\n",
        "      data += db.max_marginal_relevance_search(word, fetch_k=5, k=2)\n",
        "    word_list.append(input)\n",
        "\n",
        "    # ç¬¬äºŒå€‹ Chain å…ƒä»¶, ç”Ÿæˆåˆ†æå ±å‘Š\n",
        "    result = data_chain.invoke({'key_words':word_list,'data_content':data})\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "YWKb8jEydsoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VT7XPS8z5NS4"
      },
      "source": [
        "### 1ï¸âƒ£9ï¸âƒ£ å‘¼å«å‡½å¼"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = 'å…¬å¸çš„ç‡Ÿæ”¶ç‹€æ³å¦‚ä½•ï¼Ÿ'\n",
        "analyze_report = analyze_chain(input)\n",
        "print(analyze_report)"
      ],
      "metadata": {
        "id": "e-NHDVzqHOsU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}